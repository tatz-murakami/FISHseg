{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7c7V4yEqDc_"
   },
   "source": [
    "# Running cellpose with GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG3LSmJmLylT",
    "outputId": "44491854-c45f-40e2-ea8c-4c77b67d369b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import zarr\n",
    "from cellpose import models, core\n",
    "\n",
    "use_GPU = core.use_gpu(gpu_number=0)\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "from cellpose import utils\n",
    "from cellpose import models\n",
    "from cellpose.io import logger_setup\n",
    "logger_setup();\n",
    "\n",
    "import ray\n",
    "\n",
    "from dask import array as da\n",
    "\n",
    "import mFISHwarp.morphology\n",
    "import mFISHwarp.utils\n",
    "import napari\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset and model\n",
    "model_dir = \"/mnt/ampa02_data01/gabacoll/shared/Yuchen/model_training/crops/augment/training/models\"\n",
    "\n",
    "models_file = os.listdir(model_dir); models_file.sort()\n",
    "model_path = os.path.join(model_dir, models_file[-1])\n",
    "\n",
    "model = models.CellposeModel(gpu=use_GPU, pretrained_model=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "n5_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/fused/fused.n5'\n",
    "normalization_metadata = '/mnt/ampa02_data01/tmurakami/model_training/norm_values.pkl'\n",
    "segment_chan = 1\n",
    "reference_chan = 3\n",
    "\n",
    "# load images according to the input parameters.\n",
    "img_zarr = zarr.open(store=zarr.N5Store(n5_path), mode='r')\n",
    "n5_setups = list(img_zarr.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downsampling\n",
    "img_down_ref = img_zarr[n5_setups[reference_chan]]['timepoint0']['s4'][:]\n",
    "global_thresh = threshold_otsu(img_down_ref)\n",
    "img_mask = mFISHwarp.morphology.mask_maker(img_down_ref,global_thresh)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img_mask)\n",
    "viewer.add_image(img_down_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JRxBPmatrK7",
    "tags": []
   },
   "source": [
    "## Make overlapped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "auto_diam = False # Cellpose automatic diameter estimation.\n",
    "# theoretically, anisotropy parameter affects the accuracy. However in practice, changing this values to be the exact voxel ratio does not significantly add accuracy. \n",
    "# this may be because of the non-isotropic PSF of light-sheet.\n",
    "voxel_size = (2.0,1.3,1.3)\n",
    "anisotropy = voxel_size[1]/voxel_size[0]\n",
    "min_size = 40\n",
    "\n",
    "# Channel parameters which were used during the training.\n",
    "Training_channel = 2 # I do not know but the cellpose see the images as KRGB. If the color is green, set it to 2.\n",
    "Second_training_channel = 1\n",
    "\n",
    "# lazyly read image and convert to dask array\n",
    "chunk_size = (256,512,512)\n",
    "depth = (32,64,64) \n",
    "boundary = \"reflect\"\n",
    "\n",
    "### Make overlapping images\n",
    "# make overlapped images for both refernce and target\n",
    "overlap_imgs = []\n",
    "n5_setups = list(img_zarr.keys())\n",
    "\n",
    "# reference\n",
    "img_ref = da.from_zarr(img_zarr[n5_setups[reference_chan]]['timepoint0']['s0'])\n",
    "img_ref = da.rechunk(img_ref,chunks=chunk_size)\n",
    "overlap_imgs.append(da.overlap.overlap(img_ref, depth, boundary))\n",
    "# target\n",
    "img = da.from_zarr(img_zarr[n5_setups[segment_chan]]['timepoint0']['s0'])\n",
    "img = da.rechunk(img,chunks=chunk_size)\n",
    "overlap_imgs.append(da.overlap.overlap(img, depth, boundary))\n",
    "\n",
    "# If mask is used, calculate which chunks will be segmented\n",
    "flag_array = mFISHwarp.utils.flag_array_generator(chunk_size, img_ref.shape, img_mask)\n",
    "print(f'{flag_array.sum()} blocks of {flag_array.shape[0]}*{flag_array.shape[1]}*{flag_array.shape[2]}={flag_array.size} blocks will be calculated')\n",
    "\n",
    "# load normalization information\n",
    "norm_values = {}\n",
    "if normalization_metadata is not None:\n",
    "    norm_info = pd.read_pickle(normalization_metadata)\n",
    "    norm_values['ref_lower'] = norm_info[n5_path][reference_chan]['lower']\n",
    "    norm_values['ref_upper'] = norm_info[n5_path][reference_chan]['upper']\n",
    "    norm_values['tar_lower'] = norm_info[n5_path][segment_chan]['lower']\n",
    "    norm_values['tar_upper'] = norm_info[n5_path][segment_chan]['upper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare zarr container to save segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_overlap_zarr_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/segmentation/segmented_overlap.zarr'\n",
    "labeled_overlap_zarr = zarr.open(\n",
    "    labeled_overlap_zarr_path,\n",
    "    mode='a', \n",
    "    shape=overlap_imgs[0].shape, \n",
    "    chunks=mFISHwarp.utils.chunks_from_dask(overlap_imgs[0]), \n",
    "    dtype=np.int32)\n",
    "\n",
    "# labeled_overlap_zarr = zarr.open(labeled_overlap_zarr_path,mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=0.5,max_calls=1)\n",
    "def segmentor(\n",
    "    chunks, # list of images. reference and target\n",
    "    norm_values_ref, # list. [lower, upper]\n",
    "    norm_values_tar,\n",
    "    channels,\n",
    "    model,\n",
    "    anisotropy,\n",
    "    index,\n",
    "    min_size,\n",
    "    chunk_info,\n",
    "    zarr_file,\n",
    "):\n",
    "    # convert dask array to numpy array.\n",
    "    chunks = [i.compute() for i in chunks]\n",
    "    chunk = np.stack([\n",
    "        mFISHwarp.utils.normalization_two_values(chunks[0], norm_values_ref[0], norm_values_ref[1]),\n",
    "        mFISHwarp.utils.normalization_two_values(chunks[1], norm_values_tar[0], norm_values_tar[1])\n",
    "    ])\n",
    "\n",
    "    # precomputation to coarsly estimate cell positions\n",
    "    segments, _, _  = model.eval(chunk, channels=channels, normalize=False, z_axis=1, diameter=model.diam_mean, do_3D=True, min_size=min_size, progress=False, anisotropy=anisotropy, tile=False)\n",
    "    segments = segments.astype(np.int32)\n",
    "    \n",
    "    zarr_file[mFISHwarp.utils.obtain_chunk_slicer(chunk_info, index)] = segments\n",
    "    # return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### in case from the middle of the computation\n",
    "stored_chunks = os.listdir(labeled_overlap_zarr_path)\n",
    "stored_chunks.sort()\n",
    "\n",
    "idxs = mFISHwarp.utils.get_dask_index(overlap_imgs[0])\n",
    "chunk_info = overlap_imgs[0].chunks\n",
    "\n",
    "diameter_yx = model.diam_mean\n",
    "anisotropy = anisotropy\n",
    "# fast_mode = True\n",
    "min_size = 40\n",
    "model_type = model\n",
    "channels = [Training_channel, Second_training_channel]\n",
    "zarr_file = labeled_overlap_zarr\n",
    "\n",
    "for index in idxs:\n",
    "    if flag_array[index[0],index[1],index[2]]:\n",
    "        if '.'.join([str(i) for i in index]) not in stored_chunks:# flag == 1:\n",
    "            input_blocks = [mFISHwarp.utils.slicing_with_chunkidx(img, index) for img in overlap_imgs]\n",
    "            segmentor.remote(\n",
    "                input_blocks,\n",
    "                [norm_values['ref_lower'],norm_values['ref_upper']],\n",
    "                [norm_values['tar_lower'],norm_values['tar_upper']],\n",
    "                [Training_channel, Second_training_channel],\n",
    "                model,\n",
    "                anisotropy,\n",
    "                index,\n",
    "                min_size,\n",
    "                chunk_info,\n",
    "                zarr_file\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Those are great resource for the scaling up the segmentation'''\n",
    "# https://github.com/MouseLand/cellpose/issues/244\n",
    "# https://github.com/MouseLand/cellpose/pull/356\n",
    "# https://github.com/MouseLand/cellpose/blob/master/cellpose/contrib/distributed_segmentation.py\n",
    "# https://github.com/MouseLand/cellpose/pull/408/commits/359e480335d68caa04c7caa6ff66a089c767b63f#diff-a3c93a2a4ec84f6c33dc52001df50cd7e5afbc78482858fe54a67987772464da"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "run_cellpose_GPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cellpose2",
   "language": "python",
   "name": "cellpose2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
