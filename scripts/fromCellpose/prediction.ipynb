{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e0e8b2-e27a-4bf9-8a7c-16c93b36f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os, sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from cellpose import models, core\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "# call logger_setup to have output of cellpose written\n",
    "from cellpose.io import logger_setup\n",
    "from cellpose import utils\n",
    "\n",
    "import random\n",
    "from skimage import io\n",
    "import tqdm\n",
    "import napari\n",
    "import pandas as pd\n",
    "\n",
    "import zarr\n",
    "from dask import array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d094e22-e6ad-40ae-8600-fc3752461f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset and model\n",
    "dataset_folder = \"/mnt/ampa02_data01/gabacoll/shared/Yuchen/240417_whole_4color_1st_M037-3pb/model_training/crops\"\n",
    "aug_folder = os.path.join(dataset_folder, 'augment')\n",
    "train_folder = os.path.join(aug_folder,'training')\n",
    "models_path = os.path.join(train_folder,'models')\n",
    "\n",
    "models_file = os.listdir(models_path); models_file.sort()\n",
    "model_path = os.path.join(train_folder,'models',models_file[-1])\n",
    "\n",
    "model = models.CellposeModel(gpu=use_GPU, pretrained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d1ccaa-d4ff-4457-8b5e-ed7f8bac48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path\n",
    "fix_n5_path = '/mnt/ampa02_data01/tmurakami/240425_whole_4color_2nd_M037-3pb/fused/fused.n5' # zarr with pyramid resolution\n",
    "\n",
    "# create Zarr file object\n",
    "fix_zarr = zarr.open(store=zarr.N5Store(fix_n5_path), mode='r')\n",
    "voxel_size = (2.0,1.3,1.3)\n",
    "\n",
    "corner_positions = [1209,6600,1854]\n",
    "crop_size = [128,512,512]\n",
    "segment_chan = 0\n",
    "reference_chan = 3\n",
    "\n",
    "# Channel parameters which were used during the training.\n",
    "Training_channel = 2 # I do not know but the cellpose see the images as KRGB. If the color is green, set it to 2.\n",
    "Second_training_channel = 1\n",
    "\n",
    "# load images according to the input parameters.\n",
    "n5_setups = list(fix_zarr.keys())\n",
    "img_ref = fix_zarr[n5_setups[reference_chan]]['timepoint0']['s0']\n",
    "img_ref_ = img_ref[tuple(slice(i,i+j) for i,j in zip(corner_positions, crop_size))]\n",
    "\n",
    "img = fix_zarr[n5_setups[segment_chan]]['timepoint0']['s0']\n",
    "img_ = img[tuple(slice(i,i+j) for i,j in zip(corner_positions, crop_size))]\n",
    "\n",
    "imgs = np.stack([img_ref_,img_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d3ff3a-d0e9-4a12-b2f1-6210a77265d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 7.24 s, total: 28.1 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "# theoretically, anisotropy parameter affects the accuracy. However in practice, changing this values to be the exact voxel ratio does not significantly add accuracy. \n",
    "# this may be because of the non-isotropic PSF of light-sheet. \n",
    "anisotropy = voxel_size[1]/voxel_size[0] \n",
    "\n",
    "# with diameter\n",
    "%time masks, flows, styles  = model.eval(imgs, channels=[Training_channel,Second_training_channel], z_axis=1, diameter=model.diam_mean, do_3D=True, min_size=40, progress=True, anisotropy=anisotropy)\n",
    "# without diameter\n",
    "# %time masks, flows, styles = model.eval(imgs, channels=[Training_channel,Second_training_channel], z_axis=1, diameter=None, do_3D=True, min_size=40, progress=True, anisotropy=anisotropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "672f2737-3413-4b4f-8933-721008756f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masks' at 0x7fdf4ac0e4c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(imgs, channel_axis=0, name='image01', blending='additive')\n",
    "viewer.add_labels(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "201c2498-df7f-4323-ab7d-eaeb6006164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b54a7-d655-499b-95b8-abf9b8978b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose2",
   "language": "python",
   "name": "cellpose2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
