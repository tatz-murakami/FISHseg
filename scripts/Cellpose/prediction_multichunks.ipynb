{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7c7V4yEqDc_"
   },
   "source": [
    "# Running cellpose with GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG3LSmJmLylT",
    "outputId": "44491854-c45f-40e2-ea8c-4c77b67d369b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import zarr\n",
    "from cellpose import models, core\n",
    "\n",
    "use_GPU = core.use_gpu(gpu_number=0)\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "# from cellpose import utils\n",
    "# from cellpose import models\n",
    "# from cellpose.io import logger_setup\n",
    "# logger_setup();\n",
    "\n",
    "import ray\n",
    "\n",
    "from dask import array as da\n",
    "\n",
    "import mFISHwarp.morphology\n",
    "import mFISHwarp.utils\n",
    "import napari\n",
    "import pandas as pd\n",
    "\n",
    "from ome_zarr.io import parse_url\n",
    "from ome_zarr.reader import Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset and model\n",
    "model_dir = \"/mnt/ampa02_data01/gabacoll/shared/Yuchen/model_training/crops/augment/training/models\"\n",
    "\n",
    "models_file = os.listdir(model_dir); models_file.sort()\n",
    "model_path = os.path.join(model_dir, models_file[-1])\n",
    "\n",
    "model = models.CellposeModel(gpu=use_GPU, pretrained_model=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load N5 or Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/registration/round02.zarr'\n",
    "data_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/fused/fused.n5'\n",
    "\n",
    "_, ext = os.path.splitext(data_path)\n",
    "\n",
    "res_analysis = 0\n",
    "res_mask = 4\n",
    "\n",
    "if ext == '.n5': # n5 assume bigstitcher (bigdataviewer) format\n",
    "    ### if the original file is n5\n",
    "\n",
    "    # load images according to the input parameters.\n",
    "    img_zarr = zarr.open(store=zarr.N5Store(data_path), mode='r')\n",
    "    n5_setups = list(img_zarr.keys())\n",
    "    res_list = list(img_zarr[n5_setups[0]]['timepoint0'].keys())\n",
    "\n",
    "    imgs = []\n",
    "    imgs_mask = []\n",
    "    for setup in n5_setups:\n",
    "        imgs.append(da.from_zarr(img_zarr[setup]['timepoint0'][res_list[res_analysis]]))\n",
    "        imgs_mask.append(da.from_zarr(img_zarr[setup]['timepoint0'][res_list[res_mask]]))\n",
    "\n",
    "\n",
    "    \n",
    "elif ext == '.zarr': # zarr assumes ome-zarr\n",
    "    # read the image data\n",
    "    store = parse_url(data_path, mode=\"r\").store\n",
    "    reader = Reader(parse_url(data_path))\n",
    "    # nodes may include images, labels etc\n",
    "    nodes = list(reader())\n",
    "    # first node will be the image pixel data\n",
    "    image_node = nodes[0]\n",
    "    \n",
    "    # the first image is the highest resolution dask array. czyx.\n",
    "    dask_data = image_node.data[res_analysis]\n",
    "    dask_data_mask = image_node.data[res_mask]\n",
    "    \n",
    "    imgs = [da.squeeze(dask_data[i,...]) for i in range(dask_data.shape[0])]\n",
    "    imgs_mask = [da.squeeze(dask_data_mask[i,...]) for i in range(dask_data_mask.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I found ome-zarr does not compress in z by default. Not sure if this can cause a problem.\n",
    "# image_node.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for normalization\n",
    "normalization_metadata = '/mnt/ampa02_data01/tmurakami/model_training/norm_values.pkl'\n",
    "segment_chan = 1\n",
    "reference_chan = 3\n",
    "name_segment_chan = 'Test'\n",
    "segment_save_dir = None\n",
    "\n",
    "if segment_save_dir is None:\n",
    "    segment_save_dir = os.path.join(os.path.dirname(os.path.dirname(data_path)),'segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downsampling\n",
    "img_down_ref = imgs_mask[reference_chan][:]# img_zarr[n5_setups[reference_chan]]['timepoint0']['s4'][:]\n",
    "global_thresh = threshold_otsu(img_down_ref)\n",
    "img_mask = mFISHwarp.morphology.mask_maker(img_down_ref,global_thresh)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img_mask)\n",
    "viewer.add_image(img_down_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JRxBPmatrK7",
    "tags": []
   },
   "source": [
    "## Make overlapped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Parameters\n",
    "auto_diam = False # Cellpose automatic diameter estimation.\n",
    "# theoretically, anisotropy parameter affects the accuracy. However in practice, changing this values to be the exact voxel ratio does not significantly add accuracy. \n",
    "# this may be because of the non-isotropic PSF of light-sheet.\n",
    "voxel_size = (2.0,1.3,1.3)\n",
    "anisotropy = voxel_size[1]/voxel_size[0]\n",
    "min_size = 40\n",
    "\n",
    "# Channel parameters which were used during the training.\n",
    "Training_channel = 2 # I do not know but the cellpose see the images as KRGB. If the color is green, set it to 2.\n",
    "Second_training_channel = 1\n",
    "\n",
    "# lazyly read image and convert to dask array\n",
    "chunk_size = (256,512,512)\n",
    "depth = (32,64,64) \n",
    "boundary = \"reflect\"\n",
    "\n",
    "### Make overlapping images\n",
    "# make overlapped images for both refernce and target\n",
    "overlap_imgs = []\n",
    "\n",
    "# reference\n",
    "img_ref = imgs[reference_chan]# da.from_zarr(img_zarr[n5_setups[reference_chan]]['timepoint0']['s0'])\n",
    "img_ref = da.rechunk(img_ref,chunks=chunk_size)\n",
    "overlap_imgs.append(da.overlap.overlap(img_ref, depth, boundary))\n",
    "# target\n",
    "img = imgs[segment_chan]# da.from_zarr(img_zarr[n5_setups[segment_chan]]['timepoint0']['s0'])\n",
    "img = da.rechunk(img,chunks=chunk_size)\n",
    "overlap_imgs.append(da.overlap.overlap(img, depth, boundary))\n",
    "\n",
    "# If mask is used, calculate which chunks will be segmented\n",
    "flag_array = mFISHwarp.utils.flag_array_generator(chunk_size, img_ref.shape, img_mask)\n",
    "print(f'{flag_array.sum()} blocks of {flag_array.shape[0]}*{flag_array.shape[1]}*{flag_array.shape[2]}={flag_array.size} blocks will be calculated')\n",
    "\n",
    "# load normalization information\n",
    "norm_values = {}\n",
    "if normalization_metadata is not None:\n",
    "    norm_info = pd.read_pickle(normalization_metadata)\n",
    "    norm_values['ref_lower'] = norm_info[data_path][reference_chan]['lower']\n",
    "    norm_values['ref_upper'] = norm_info[data_path][reference_chan]['upper']\n",
    "    norm_values['tar_lower'] = norm_info[data_path][segment_chan]['lower']\n",
    "    norm_values['tar_upper'] = norm_info[data_path][segment_chan]['upper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare zarr container to save segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_overlap_zarr_path = os.path.join(segment_save_dir,name_segment_chan,'segmented_overlap.zarr')\n",
    "labeled_overlap_zarr = zarr.open(\n",
    "    labeled_overlap_zarr_path,\n",
    "    mode='a', \n",
    "    shape=overlap_imgs[0].shape, \n",
    "    chunks=mFISHwarp.utils.chunks_from_dask(overlap_imgs[0]), \n",
    "    dtype=np.int32)\n",
    "\n",
    "# labeled_overlap_zarr = zarr.open(labeled_overlap_zarr_path,mode='a')\n",
    "\n",
    "prob_overlap_zarr_path = os.path.join(segment_save_dir,name_segment_chan,'prob_overlap.zarr')\n",
    "prob_overlap_zarr = zarr.open(\n",
    "    prob_overlap_zarr_path,\n",
    "    mode='a', \n",
    "    shape=overlap_imgs[0].shape, \n",
    "    chunks=mFISHwarp.utils.chunks_from_dask(overlap_imgs[0]), \n",
    "    dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=0.5,max_calls=1)\n",
    "def segmentor(\n",
    "    chunks, # list of images. reference and target\n",
    "    norm_values_ref, # list. [lower, upper]\n",
    "    norm_values_tar,\n",
    "    channels,\n",
    "    model,\n",
    "    anisotropy,\n",
    "    index,\n",
    "    min_size,\n",
    "    chunk_info,\n",
    "    zarr_file,\n",
    "    prob_zarr_file=None\n",
    "):\n",
    "    # convert dask array to numpy array.\n",
    "    chunks = [i.compute() for i in chunks]\n",
    "    chunk = np.stack([\n",
    "        mFISHwarp.utils.normalization_two_values(chunks[0], norm_values_ref[0], norm_values_ref[1]),\n",
    "        mFISHwarp.utils.normalization_two_values(chunks[1], norm_values_tar[0], norm_values_tar[1])\n",
    "    ])\n",
    "\n",
    "    # precomputation to coarsly estimate cell positions\n",
    "    segments, flow, _  = model.eval(chunk, channels=channels, normalize=False, z_axis=1, diameter=model.diam_mean, do_3D=True, min_size=min_size, progress=False, anisotropy=anisotropy, tile=False)\n",
    "    segments = segments.astype(np.int32)\n",
    "    prob = flow[2].astype(np.float16) # float 16 to save data size\n",
    "    \n",
    "    zarr_file[mFISHwarp.utils.obtain_chunk_slicer(chunk_info, index)] = segments\n",
    "    if prob_zarr_file is not None:\n",
    "        prob_zarr_file[mFISHwarp.utils.obtain_chunk_slicer(chunk_info, index)] = prob\n",
    "    # return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### in case from the middle of the computation\n",
    "stored_chunks = os.listdir(labeled_overlap_zarr_path)\n",
    "stored_chunks.sort()\n",
    "\n",
    "idxs = mFISHwarp.utils.get_dask_index(overlap_imgs[0])\n",
    "chunk_info = overlap_imgs[0].chunks\n",
    "\n",
    "diameter_yx = model.diam_mean\n",
    "anisotropy = anisotropy\n",
    "# fast_mode = True\n",
    "min_size = 40\n",
    "model_type = model\n",
    "channels = [Training_channel, Second_training_channel]\n",
    "\n",
    "for index in idxs:\n",
    "    if flag_array[index[0],index[1],index[2]]:\n",
    "        if '.'.join([str(i) for i in index]) not in stored_chunks:# flag == 1:\n",
    "            input_blocks = [mFISHwarp.utils.slicing_with_chunkidx(img, index) for img in overlap_imgs]\n",
    "            segmentor.remote(\n",
    "                input_blocks,\n",
    "                [norm_values['ref_lower'],norm_values['ref_upper']],\n",
    "                [norm_values['tar_lower'],norm_values['tar_upper']],\n",
    "                [Training_channel, Second_training_channel],\n",
    "                model,\n",
    "                anisotropy,\n",
    "                index,\n",
    "                min_size,\n",
    "                chunk_info,\n",
    "                labeled_overlap_zarr,\n",
    "                prob_overlap_zarr\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "run_cellpose_GPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cellpose2",
   "language": "python",
   "name": "cellpose2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
