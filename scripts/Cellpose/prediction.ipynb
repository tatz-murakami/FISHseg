{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e0e8b2-e27a-4bf9-8a7c-16c93b36f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from cellpose import models, core\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "# call logger_setup to have output of cellpose written\n",
    "# from cellpose.io import logger_setup\n",
    "# from cellpose import utils\n",
    "\n",
    "from skimage import io\n",
    "import tqdm\n",
    "import napari\n",
    "import pandas as pd\n",
    "\n",
    "import zarr\n",
    "from dask import array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b61d89-a953-484b-a4cd-a2c10b13734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_two_values(arr, lower, upper):\n",
    "    \"\"\"\n",
    "    Normalize array so that the lower values to be 0 and upper values to be 1.\n",
    "    \"\"\"\n",
    "    return (arr - lower) / (upper - lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d094e22-e6ad-40ae-8600-fc3752461f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset and model\n",
    "dataset_folder = \"/mnt/ampa02_data01/gabacoll/shared/Yuchen/model_training/crops\"\n",
    "aug_folder = os.path.join(dataset_folder, 'augment')\n",
    "train_folder = os.path.join(aug_folder,'training')\n",
    "models_path = os.path.join(train_folder,'models')\n",
    "\n",
    "models_file = os.listdir(models_path); models_file.sort()\n",
    "model_path = os.path.join(train_folder,'models',models_file[-1])\n",
    "\n",
    "model = models.CellposeModel(gpu=use_GPU, pretrained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1ccaa-d4ff-4457-8b5e-ed7f8bac48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path\n",
    "n5_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/fused/fused.n5' # zarr with pyramid resolution\n",
    "normalization_metadata = '/mnt/ampa02_data01/tmurakami/model_training/norm_values.pkl' # Or None\n",
    "\n",
    "# create Zarr file object\n",
    "img_zarr = zarr.open(store=zarr.N5Store(n5_path), mode='r')\n",
    "voxel_size = (2.0,1.3,1.3)\n",
    "\n",
    "corner_positions = [1783,2093,2955]\n",
    "crop_size = [128,512,512]\n",
    "segment_chan = 1\n",
    "reference_chan = 3\n",
    "auto_diam = False # Cellpose automatic diameter estimation.\n",
    "min_size = 40\n",
    "\n",
    "# theoretically, anisotropy parameter affects the accuracy. However in practice, changing this values to be the exact voxel ratio does not significantly add accuracy. \n",
    "# this may be because of the non-isotropic PSF of light-sheet. \n",
    "anisotropy = voxel_size[1]/voxel_size[0] \n",
    "\n",
    "# Channel parameters which were used during the training.\n",
    "Training_channel = 2 # I do not know but the cellpose see the images as KRGB. If the color is green, set it to 2.\n",
    "Second_training_channel = 1\n",
    "\n",
    "# load images according to the input parameters.\n",
    "n5_setups = list(img_zarr.keys())\n",
    "img_ref = img_zarr[n5_setups[reference_chan]]['timepoint0']['s0']\n",
    "img_ref_ = img_ref[tuple(slice(i,i+j) for i,j in zip(corner_positions, crop_size))]\n",
    "\n",
    "img = img_zarr[n5_setups[segment_chan]]['timepoint0']['s0']\n",
    "img_ = img[tuple(slice(i,i+j) for i,j in zip(corner_positions, crop_size))]\n",
    "\n",
    "if normalization_metadata is not None:\n",
    "    norm_info = pd.read_pickle(normalization_metadata)\n",
    "    img_ref_ = normalization_two_values(img_ref_.astype(float), norm_info[n5_path][reference_chan]['lower'], norm_info[n5_path][reference_chan]['upper'])\n",
    "    img_ = normalization_two_values(img_.astype(float), norm_info[n5_path][segment_chan]['lower'], norm_info[n5_path][segment_chan]['upper'])\n",
    "    # img_ = normalization_two_values(img_.astype(float), norm_info[n5_path][segment_chan]['lower'], 5000)\n",
    "\n",
    "imgs = np.stack([img_ref_,img_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3ff3a-d0e9-4a12-b2f1-6210a77265d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "if normalization_metadata is not None:\n",
    "    if ~auto_diam:\n",
    "        # with diameter parameter provided without Cellpose normalization\n",
    "        %time masks, flows, styles  = model.eval(imgs, channels=[Training_channel,Second_training_channel], normalize=False, z_axis=1, diameter=model.diam_mean, do_3D=True, min_size=min_size, progress=True, anisotropy=anisotropy)\n",
    "    else:\n",
    "        %time masks, flows, styles  = model.eval(imgs, channels=[Training_channel,Second_training_channel], normalize=False, z_axis=1, diameter=None, do_3D=True, min_size=min_size, progress=True, anisotropy=anisotropy)\n",
    "else:\n",
    "    if ~auto_diam:\n",
    "        # with diameter parameter provided \n",
    "        %time masks, flows, styles  = model.eval(imgs, channels=[Training_channel,Second_training_channel], z_axis=1, diameter=model.diam_mean, do_3D=True, min_size=min_size, progress=True, anisotropy=anisotropy)\n",
    "    else:\n",
    "        # without diameter\n",
    "        %time masks, flows, styles = model.eval(imgs, channels=[Training_channel,Second_training_channel], z_axis=1, diameter=None, do_3D=True, min_size=min_size, progress=True, anisotropy=anisotropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f2737-3413-4b4f-8933-721008756f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(imgs, channel_axis=0, name='image01', blending='additive')\n",
    "viewer.add_labels(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57261157-695d-4db4-9ff4-5dc1821b8803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose2",
   "language": "python",
   "name": "cellpose2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
