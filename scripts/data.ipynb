{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cbe40-4b8a-4daa-9482-4f3a1be268ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "import napari\n",
    "import pandas as pd\n",
    "\n",
    "import zarr\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820e5d1-a6ab-4900-a97e-967646eceded",
   "metadata": {},
   "source": [
    "### Make data for training\n",
    "Assume training data is double color. One for the channel and another for Cytosol/nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b40fd2-9e1b-4561-a547-677757e2370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path\n",
    "fix_n5_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/fused/fused.n5' # zarr with pyramid resolution\n",
    "# save path\n",
    "save_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/model_training/crops'\n",
    "# metadata path\n",
    "meta_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/model_training/info.pkl'\n",
    "\n",
    "# create Zarr file object\n",
    "fix_zarr = zarr.open(store=zarr.N5Store(fix_n5_path), mode='r')\n",
    "# if you use ngff ome.zarr\n",
    "# mov_zarr_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/registration/round02.zarr'\n",
    "# mov_zarr = zarr.open(mov_zarr_path, mode='r')\n",
    "\n",
    "n5_setups = list(fix_zarr.keys())\n",
    "\n",
    "voxel_size = (2.0,1.3,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e51507-0a99-4f5d-b8e5-03b3ba5f07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your parameters here\n",
    "reference_chan = 3 # Number or None\n",
    "segment_chan = 2\n",
    "\n",
    "# set corner positions. I suggest finding the positions using BigDataViewer or relevant.\n",
    "corner_positions = [\n",
    "    [1235,2510,776],\n",
    "    [1325,3350,1543],\n",
    "    [1725,4632,1604],\n",
    "    [2262,6207,2682],\n",
    "    [1708,3877,2563]\n",
    "]\n",
    "\n",
    "# [100,256,256] crop size and FoV [100,768,768] are recommended for the 2D annotation\n",
    "crop_size = [100,256,256]\n",
    "FoV = [100,768,768]\n",
    "\n",
    "# set True for 2D annotation and set False for 3D annotation\n",
    "select_plane = True\n",
    "\n",
    "# processing of parameters\n",
    "if not all([(j-i)>=0 for i,j in zip(crop_size, FoV)]):\n",
    "    raise ValueError('FoV should be larger than crop_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f4fe5-a1db-46b2-b4b0-0e5b635b3f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make metadata file if it does not exist.\n",
    "if not os.path.exists(meta_path):\n",
    "    df = pd.DataFrame(columns=['ID', 'integer_ID', 'instance_counts', 'corner', 'source', 'ref_channel', 'channel', 'crop_size'])\n",
    "else:\n",
    "    df = pd.read_pickle(meta_path)\n",
    "\n",
    "for i, pos in enumerate(corner_positions):\n",
    "    print(f\"The index {i} with the position {pos}\")\n",
    "    idx = len(df)\n",
    "    \n",
    "    # find out any duplication between the current data and the metadata\n",
    "    # if it is duplicated, ask \n",
    "    flag = False\n",
    "    if df['corner'].isin([pos]).any():\n",
    "        for k in df['integer_ID'][df['corner'].isin([pos])].to_list():\n",
    "            if ((df.loc[k,'source'] == fix_n5_path) and \n",
    "                (df.loc[k,'ref_channel'] == reference_chan) and \n",
    "                (df.loc[k,'channel'] == segment_chan) and \n",
    "                (df.loc[k,'crop_size'] == crop_size) and\n",
    "                (df.loc[k,'select_plane'] == select_plane)):\n",
    "                flag = True\n",
    "                idx = k\n",
    "    if flag:\n",
    "        ans = input(\"Do you want to re-analyze the data? y or n\")\n",
    "        if ans != 'y':\n",
    "            continue\n",
    "        \n",
    "    # set file path to be saved for both image and mask\n",
    "    prefix = str(idx)\n",
    "    while len(prefix) < 4:\n",
    "        prefix = '0' + prefix\n",
    "    img_path = os.path.join(save_path, prefix+'_img.tif')\n",
    "    mask_path = os.path.join(save_path, prefix+'_mask.tif')\n",
    "\n",
    "\n",
    "\n",
    "    # get the image of a channel to be segmented\n",
    "    FoV_stack = []\n",
    "    img = fix_zarr[n5_setups[segment_chan]]['timepoint0']['s0']\n",
    "\n",
    "    # set the corner of FoV in napari\n",
    "    top_corner = tuple(i-(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    bottom_corner = tuple(i+j+(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    top_corner = tuple(j if j>=i else i for i,j in zip([0,0,0],top_corner))\n",
    "    bottom_corner = tuple(j if j<=i else i for i,j in zip(img.shape,bottom_corner))\n",
    "    \n",
    "    # prepare to make border lines\n",
    "    top_border_corner = tuple((k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    bottom_border_corner = tuple(j+(k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    \n",
    "    FoV_segment = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "    \n",
    "    # get the image of a reference of channel\n",
    "    if reference_chan is not None:\n",
    "        img = fix_zarr[n5_setups[reference_chan]]['timepoint0']['s0']\n",
    "        FoV_reference = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "        FoV_stack.append(FoV_reference)\n",
    "    \n",
    "    FoV_stack.append(FoV_segment)\n",
    "    FoV_stack = np.stack(FoV_stack)\n",
    "\n",
    "    # open Napari. Pause for loop until close the window\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(FoV_stack, channel_axis=0, scale=voxel_size, contrast_limits=[0,65535])\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]]],\n",
    "                      edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    labels = viewer.add_labels(np.zeros_like(FoV_segment), name='segmentation', scale=voxel_size)\n",
    "    viewer.show(block=True)\n",
    "    \n",
    "    sub_area_slicer = tuple(slice(i,j) for i,j in zip(top_border_corner,bottom_border_corner))\n",
    "\n",
    "    # save images and segmentation.\n",
    "    img = np.swapaxes(FoV_stack[(slice(0,None),)+sub_area_slicer],0,1)\n",
    "    labels_img = labels.data[sub_area_slicer]\n",
    "    \n",
    "    if select_plane:\n",
    "        plane_pos = np.argmax((labels.data>0).sum(axis=(1,2)))\n",
    "        img = img[plane_pos,...]\n",
    "        labels_img = labels_img[plane_pos,...]\n",
    "        \n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'CYX'})\n",
    "        io.imsave(mask_path, labels_img, plugin='tifffile')\n",
    "\n",
    "    else:\n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'ZCYX'})\n",
    "        io.imsave(mask_path, labels_img, plugin='tifffile')\n",
    "\n",
    "    # update the metadata\n",
    "    df.loc[idx,'ID'] = prefix\n",
    "    df.loc[idx,'integer_ID'] = idx\n",
    "    count = (np.unique(labels_img)).size - 1\n",
    "    df.loc[idx,'instance_counts'] = count\n",
    "    df.at[idx,'corner'] = pos\n",
    "    df.loc[idx, 'source'] = fix_n5_path\n",
    "    df.loc[idx, 'ref_channel'] = reference_chan\n",
    "    df.loc[idx, 'channel'] = segment_chan\n",
    "    df.at[idx, 'crop_size'] = crop_size\n",
    "    df.loc[idx, 'select_plane'] = select_plane\n",
    "\n",
    "# pickle the metadata\n",
    "df.to_pickle(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7c954-a5df-4826-8540-1e9333ad15fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsfm02",
   "language": "python",
   "name": "lsfm02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
